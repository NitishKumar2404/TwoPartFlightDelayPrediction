{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1\n",
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to be Considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flights Data Pathnames\n",
    "dirpath = \"Data/Flight/\"\n",
    "dirname = \"On_Time_On_Time_Performance_\"\n",
    "flightpathname = list()\n",
    "for i in (2016,2017):\n",
    "    i = str(i)\n",
    "    for j in range(1,13):\n",
    "        j = str(j)\n",
    "        filename = dirname + i + \"_\" + j\n",
    "        pathname = dirpath + i + \"/\" + filename + \"/\" + filename + \".csv\"\n",
    "        flightpathname.append(pathname)\n",
    "\n",
    "\n",
    "## Weather Data\n",
    "aircodes = ['ATL', 'CLT', 'DEN', 'DFW', 'EWR', 'IAH', 'JFK', 'LAS', 'LAX', 'MCO', 'MIA', 'ORD', 'PHX', 'SEA', 'SFO']\n",
    "\n",
    "#Weather Factors to consider\n",
    "weatherfactor = ['date', 'time', 'airport', 'windspeedKmph', 'winddirDegree', 'precipMM', 'visibility', 'pressure', 'cloudcover', 'DewPointF', 'WindGustKmph', 'humidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Flight Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = list()\n",
    "for i in flightpathname:   \n",
    "    dataframe1 = pd.read_csv(i, encoding = 'utf-8', low_memory = False)\n",
    "    dataframe1  = dataframe1[['FlightDate', 'Quarter' ,'Year' ,'Month' , 'DayofMonth' ,'Origin','CRSDepTime', 'DepTime', 'DepDelay', 'DepDelayMinutes', 'Dest','CRSArrTime','ArrTime', 'ArrDelay', 'ArrDelayMinutes']]\n",
    "    dataframe1['FlightDate'] = pd.to_datetime(dataframe1['FlightDate'])\n",
    "    acdatf = list()\n",
    "    for i in aircodes:\n",
    "        dtf = dataframe1[(dataframe1.Dest == i)]\n",
    "        acdatf.append(dtf)\n",
    "    dataframe1 = pd.concat(acdatf)\n",
    "    dataframes.append(dataframe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes)\n",
    "df.to_csv(\"Data/TotalFlightsData.csv\", index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"Data/weather/\"\n",
    "weatherdata = dict()\n",
    "for i in weatherfactor:\n",
    "    weatherdata[i] = list()\n",
    "for k in aircodes:\n",
    "    for i in (2016, 2017):\n",
    "        i = str(i)\n",
    "        for j in range(1,13):\n",
    "            j = str(j)\n",
    "            p = dirpath + k + \"/\" + i + \"-\" + j + \".json\"\n",
    "            data = json.load(open(p))['data']['weather']\n",
    "            for d in data:\n",
    "                date = d['date']\n",
    "                d = d['hourly']\n",
    "                for t in d:\n",
    "                    weatherdata['airport'].append(k)\n",
    "                    weatherdata['date'].append(date)\n",
    "                    for keys in weatherfactor:\n",
    "                        try:\n",
    "                            weatherdata[keys].append(t[keys])\n",
    "                        except:\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdataf = pd.DataFrame(weatherdata, columns = weatherfactor)\n",
    "wdataf['date'] = pd.to_datetime(wdataf['date'])\n",
    "wdataf.to_csv(\"Data/TotalWeatherData.csv\", index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Weather and Flight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdatf = pd.read_csv(\"Data/TotalFlightsData.csv\", encoding = 'utf-8')\n",
    "wdatf = pd.read_csv(\"Data/TotalWeatherData.csv\", encoding = 'utf-8')\n",
    "dates = wdatf['date']\n",
    "dates = dict(dates.value_counts(ascending = True))\n",
    "dates = [k for k,v in dates.items()]\n",
    "dates.sort()\n",
    "time = wdatf['time']\n",
    "time = dict(time.value_counts())\n",
    "time = [k for k,v in time.items()]\n",
    "time.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running aircode : ATL\n",
      "Running aircode : CLT\n",
      "Running aircode : DEN\n",
      "Running aircode : DFW\n",
      "Running aircode : EWR\n",
      "Running aircode : IAH\n",
      "Running aircode : JFK\n",
      "Running aircode : LAS\n",
      "Running aircode : LAX\n",
      "Running aircode : MCO\n",
      "Running aircode : MIA\n",
      "Running aircode : ORD\n",
      "Running aircode : PHX\n",
      "Running aircode : SEA\n",
      "Running aircode : SFO\n"
     ]
    }
   ],
   "source": [
    "fdataframe = list()\n",
    "for i in aircodes:\n",
    "    fdaircode = fdatf[(fdatf.Dest == i)]\n",
    "    wdaircode = wdatf[(wdatf.airport == i)]\n",
    "    airportdatf = list()\n",
    "    print(\"Running aircode :\", i)\n",
    "    for j in dates:\n",
    "        fddates = fdaircode[(fdaircode.FlightDate == j)]\n",
    "        wddates = wdaircode[(wdaircode.date == j)]\n",
    "        datedataframes = list()\n",
    "        for k in range(0, len(time)):\n",
    "            if time[k] == 2300:\n",
    "                fdtime = fddates[(fddates.CRSArrTime >= time[k])]\n",
    "                numrows = len(fdtime.index)\n",
    "                if numrows == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    wdtime = wddates[(wddates.time == time[k])]\n",
    "                    wdtime = wdtime[['windspeedKmph', 'winddirDegree', 'precipMM', 'visibility', 'pressure', 'cloudcover', 'DewPointF', 'WindGustKmph', 'humidity']]\n",
    "                    wdt = pd.concat([wdtime] * numrows, ignore_index = True)\n",
    "                    timedatf = pd.concat([fdtime.reset_index(drop = True), wdt.reset_index(drop = True)], axis = 1,ignore_index = True, sort = False)\n",
    "                    datedataframes.append(timedatf)\n",
    "            else:\n",
    "                fdtime = fddates[(fddates.CRSArrTime >= time[k]) & (fddates.CRSArrTime < time[k+1])]\n",
    "                numrows = len(fdtime.index)\n",
    "                if numrows == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    wdtime = wddates[(wddates.time == time[k])]\n",
    "                    wdtime = wdtime[['windspeedKmph', 'winddirDegree', 'precipMM', 'visibility', 'pressure', 'cloudcover', 'DewPointF', 'WindGustKmph', 'humidity']]\n",
    "                    wdt = pd.concat([wdtime] * numrows, ignore_index = True)\n",
    "                    timedatf = pd.concat([fdtime.reset_index(drop = True), wdt.reset_index(drop = True)], axis = 1,ignore_index = True, sort = False)\n",
    "                    datedataframes.append(timedatf)\n",
    "        airportdatf.append(pd.concat(datedataframes, ignore_index = True))\n",
    "    fdataframe.append(pd.concat(airportdatf, ignore_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finaldatf = pd.concat(fdataframe, ignore_index = True)\n",
    "finaldatf = finaldatf.rename(columns = {0 : 'FlightDate', 1 : 'Quarter' ,2 : 'Year' ,3 : 'Month' ,4 : 'DayofMonth' ,5 : 'Origin',6 : 'CRSDepTime',7 : 'DepTime',8 : 'DepDelay',9 : 'DepDelayMinutes',10 : 'Dest',11 : 'CRSArrTime',12 : 'ArrTime', 13 : 'ArrDelay',14 : 'ArrDelayMinutes',15 : 'windspeedKmph',16 : 'winddirDegree', 17 : 'precipMM',18 : 'visibility',19 : 'pressure',20 : 'cloudcover', 21 : 'DewPointF', 22 : 'WindGustKmph', 23 : 'humidity'})\n",
    "finaldatf.to_csv(\"Data/FinalData.csv\", index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"Data/FinalData.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdatf = dataframe.iloc[0:5050000]\n",
    "testdatf = dataframe.iloc[5050000:5055592]\n",
    "testdatf = dataframe[['FlightDate', 'Quarter' ,'Year' ,'Month' , 'DayofMonth' ,'Origin','CRSDepTime', 'Dest','CRSArrTime','windspeedKmph', 'winddirDegree', 'precipMM', 'visibility', 'pressure', 'cloudcover', 'DewPointF', 'WindGustKmph', 'humidity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdatf.to_csv(\"Data/TrainingData.csv\", index = False, encoding = \"utf-8\")\n",
    "testdatf.to_csv(\"Data/TestData.csv\", index = False, encoding = \"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
